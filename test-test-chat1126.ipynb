{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":13881489,"sourceType":"datasetVersion","datasetId":8844121}],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os, gc\nimport numpy as np\nimport pandas as pd\nfrom tqdm import tqdm\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import f1_score\n\nimport lightgbm as lgb\nimport xgboost as xgb\nfrom catboost import CatBoostClassifier\n\nnp.random.seed(42)\n\nDATA_DIR = \"/kaggle/input/123456\"\n\ntrain_log = pd.read_csv(f\"{DATA_DIR}/train_log.csv\")\ntest_log  = pd.read_csv(f\"{DATA_DIR}/test_log.csv\")\n\nprint(\"Cell 1 OK — Data Loaded.\")\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-11-27T11:24:46.208385Z","iopub.execute_input":"2025-11-27T11:24:46.208681Z","iopub.status.idle":"2025-11-27T11:24:46.446242Z","shell.execute_reply.started":"2025-11-27T11:24:46.208660Z","shell.execute_reply":"2025-11-27T11:24:46.445541Z"}},"outputs":[{"name":"stdout","text":"Cell 1 OK — Data Loaded.\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"def build_features_from_lightcurves(df):\n    df = df.sort_values([\"object_id\", \"Filter\", \"Time (MJD)\"])\n\n    df[\"w\"] = 1.0 / (df[\"Flux_err\"]**2 + 1e-9)\n    df[\"flux_w\"] = df[\"Flux\"] * df[\"w\"]\n\n    aggs = {\n        \"Flux\": [\"min\",\"max\",\"mean\",\"median\",\"std\"],\n        \"Flux_err\": [\"mean\"],\n        \"Time (MJD)\": [\"min\",\"max\",\"count\"],\n        \"w\": [\"sum\"],\n        \"flux_w\": [\"sum\"]\n    }\n\n    agg = df.groupby([\"object_id\",\"Filter\"]).agg(aggs)\n    agg.columns = [f\"{a}_{b}\" for a,b in agg.columns]\n    agg = agg.reset_index()\n\n    agg[\"flux_amp\"] = agg[\"Flux_max\"] - agg[\"Flux_min\"]\n    agg[\"flux_rel_amp\"] = agg[\"flux_amp\"]/(agg[\"Flux_mean\"]+1e-9)\n    agg[\"time_span\"] = agg[\"Time (MJD)_max\"] - agg[\"Time (MJD)_min\"]\n    agg[\"flux_w_mean\"] = agg[\"flux_w_sum\"]/(agg[\"w_sum\"]+1e-9)\n\n    agg[\"slope\"] = (agg[\"Flux_max\"] - agg[\"Flux_min\"]) / (agg[\"Time (MJD)_max\"] - agg[\"Time (MJD)_min\"] + 1e-9)\n    agg[\"asymmetry\"] = (agg[\"Flux_mean\"] - agg[\"Flux_median\"]) / (agg[\"Flux_std\"] + 1e-9)\n    agg[\"peak_sharpness\"] = (agg[\"Flux_max\"] - agg[\"Flux_mean\"]) / (agg[\"Flux_std\"] + 1e-9)\n\n    agg.drop(columns=[\"flux_w_sum\",\"w_sum\"], inplace=True)\n\n    agg[\"has_filter\"] = 1\n    filt = agg.pivot(index=\"object_id\", columns=\"Filter\", values=\"has_filter\").fillna(0)\n    filt.columns = [f\"has_{c}\" for c in filt.columns]\n\n    numeric_cols = [c for c in agg.columns if c not in [\"object_id\",\"Filter\",\"has_filter\"]]\n    wide = agg.pivot(index=\"object_id\", columns=\"Filter\", values=numeric_cols)\n    wide.columns = [f\"{c[0]}_{c[1]}\" for c in wide.columns]\n    wide = wide.reset_index().fillna(0)\n\n    return wide.merge(filt.reset_index(), on=\"object_id\", how=\"left\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-27T11:24:46.447242Z","iopub.execute_input":"2025-11-27T11:24:46.447471Z","iopub.status.idle":"2025-11-27T11:24:46.455478Z","shell.execute_reply.started":"2025-11-27T11:24:46.447454Z","shell.execute_reply":"2025-11-27T11:24:46.454787Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"def load_splits(split_ids, mode=\"train\"):\n    all_feats = []\n    for i in split_ids:\n        fname = f\"{DATA_DIR}/split_{i:02d}/{mode}_full_lightcurves.csv\"\n        if os.path.exists(fname):\n            df = pd.read_csv(fname)\n            feats = build_features_from_lightcurves(df)\n            all_feats.append(feats)\n            del df\n            gc.collect()\n    full = pd.concat(all_feats, ignore_index=True)\n    return full.groupby(\"object_id\",as_index=False).mean()\n\nprint(\"Loading TRAIN splits...\")\ntrain_feats = load_splits(range(1,21), mode=\"train\")\n\ntrain = train_feats.merge(\n    train_log[[\"object_id\",\"Z\",\"Z_err\",\"EBV\",\"target\"]],\n    on=\"object_id\", how=\"left\"\n).fillna(0)\n\nfor c in train.columns:\n    if \"flux_w_mean\" in c:\n        train[c+\"_x_Z\"] = train[c]*train[\"Z\"]\n\nfeature_cols = [c for c in train.columns if c not in [\"object_id\",\"target\"]]\nX = train[feature_cols].values\ny = train[\"target\"].values\n\nprint(\"Train shape:\", train.shape)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-27T11:24:46.456670Z","iopub.execute_input":"2025-11-27T11:24:46.456967Z","iopub.status.idle":"2025-11-27T11:24:49.829518Z","shell.execute_reply.started":"2025-11-27T11:24:46.456943Z","shell.execute_reply":"2025-11-27T11:24:49.828863Z"}},"outputs":[{"name":"stdout","text":"Loading TRAIN splits...\nTrain shape: (3043, 113)\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"N_FOLDS = 5\nskf = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=42)\n\noof_preds = np.zeros(X.shape[0])\n\nmodels_lgb = []\nmodels_xgb = []\nmodels_cat = []\n\npos = (y==1).sum()\nneg = (y==0).sum()\nscale_pos_weight = neg/(pos+1)\n\nparams_lgb = {\n    \"objective\":\"binary\",\n    \"metric\":\"binary_logloss\",\n    \"learning_rate\":0.03,\n    \"num_leaves\":96,\n    \"feature_fraction\":0.7,\n    \"bagging_fraction\":0.7,\n    \"bagging_freq\":1,\n    \"scale_pos_weight\":scale_pos_weight,\n    \"verbosity\":-1,\n}\n\nparams_xgb = {\n    \"max_depth\":7,\n    \"eta\":0.03,\n    \"subsample\":0.7,\n    \"colsample_bytree\":0.7,\n    \"objective\":\"binary:logistic\",\n    \"eval_metric\":\"logloss\",\n    \"scale_pos_weight\":scale_pos_weight,\n    \"tree_method\":\"hist\",\n}\n\nprint(\"Start 3-model Ensemble Training...\")\n\nfor fold,(tr,va) in enumerate(skf.split(X,y)):\n    print(f\"\\n=== FOLD {fold+1}/{N_FOLDS} ===\")\n\n    Xtr, ytr = X[tr], y[tr]\n    Xva, yva = X[va], y[va]\n\n    # LightGBM\n    dtr_lgb = lgb.Dataset(Xtr,label=ytr)\n    dva_lgb = lgb.Dataset(Xva,label=yva)\n    m_lgb = lgb.train(\n        params_lgb, dtr_lgb, num_boost_round=1000,\n        valid_sets=[dtr_lgb,dva_lgb],\n        callbacks=[lgb.early_stopping(50), lgb.log_evaluation(0)]\n    )\n    models_lgb.append(m_lgb)\n    pred_lgb = m_lgb.predict(Xva)\n\n    # XGBoost\n    dtr_xgb = xgb.DMatrix(Xtr,label=ytr)\n    dva_xgb = xgb.DMatrix(Xva,label=yva)\n    m_xgb = xgb.train(\n        params_xgb, dtr_xgb, num_boost_round=1200,\n        evals=[(dva_xgb,\"eval\")],\n        early_stopping_rounds=80,\n        verbose_eval=False\n    )\n    models_xgb.append(m_xgb)\n    pred_xgb = m_xgb.predict(dva_xgb)\n\n    # CatBoost\n    m_cat = CatBoostClassifier(\n        depth=8,\n        learning_rate=0.03,\n        iterations=1500,\n        loss_function=\"Logloss\",\n        eval_metric=\"Logloss\",\n        random_seed=42,\n        verbose=False\n    )\n    m_cat.fit(Xtr, ytr, eval_set=(Xva,yva))\n    models_cat.append(m_cat)\n    pred_cat = m_cat.predict_proba(Xva)[:,1]\n\n    # Ensemble → OOF\n    oof_preds[va] = (pred_lgb + pred_xgb + pred_cat) / 3\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-27T11:24:49.830655Z","iopub.execute_input":"2025-11-27T11:24:49.831048Z","iopub.status.idle":"2025-11-27T11:28:34.263462Z","shell.execute_reply.started":"2025-11-27T11:24:49.831034Z","shell.execute_reply":"2025-11-27T11:28:34.262700Z"}},"outputs":[{"name":"stdout","text":"Start 3-model Ensemble Training...\n\n=== FOLD 1/5 ===\nTraining until validation scores don't improve for 50 rounds\nEarly stopping, best iteration is:\n[107]\ttraining's binary_logloss: 0.0271958\tvalid_1's binary_logloss: 0.129881\n\n=== FOLD 2/5 ===\nTraining until validation scores don't improve for 50 rounds\nEarly stopping, best iteration is:\n[71]\ttraining's binary_logloss: 0.0423343\tvalid_1's binary_logloss: 0.145148\n\n=== FOLD 3/5 ===\nTraining until validation scores don't improve for 50 rounds\nEarly stopping, best iteration is:\n[97]\ttraining's binary_logloss: 0.0294382\tvalid_1's binary_logloss: 0.131961\n\n=== FOLD 4/5 ===\nTraining until validation scores don't improve for 50 rounds\nEarly stopping, best iteration is:\n[88]\ttraining's binary_logloss: 0.0348331\tvalid_1's binary_logloss: 0.14398\n\n=== FOLD 5/5 ===\nTraining until validation scores don't improve for 50 rounds\nEarly stopping, best iteration is:\n[82]\ttraining's binary_logloss: 0.0377144\tvalid_1's binary_logloss: 0.149949\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"best_thr = 0\nbest_f1 = 0\n\nths = np.linspace(0.05,0.40,200)\nfor t in ths:\n    f1 = f1_score(y, (oof_preds>=t).astype(int))\n    if f1>best_f1:\n        best_f1 = f1\n        best_thr = t\n\nprint(\"Best OOF threshold =\", best_thr)\nprint(\"Best OOF F1 =\", best_f1)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-27T11:28:34.264155Z","iopub.execute_input":"2025-11-27T11:28:34.264325Z","iopub.status.idle":"2025-11-27T11:28:34.503044Z","shell.execute_reply.started":"2025-11-27T11:28:34.264312Z","shell.execute_reply":"2025-11-27T11:28:34.501956Z"}},"outputs":[{"name":"stdout","text":"Best OOF threshold = 0.1801507537688442\nBest OOF F1 = 0.4125\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"print(\"Loading TEST splits...\")\ntest_feats = load_splits(range(1,21), mode=\"test\")\n\ntest = test_feats.merge(\n    test_log[[\"object_id\",\"Z\",\"Z_err\",\"EBV\"]],\n    on=\"object_id\", how=\"left\"\n).fillna(0)\n\nfor c in test.columns:\n    if \"flux_w_mean\" in c:\n        test[c+\"_x_Z\"] = test[c]*test[\"Z\"]\n\nX_test = test[feature_cols].values\ndtest  = xgb.DMatrix(X_test)\n\nsub_preds = np.zeros(X_test.shape[0])\n\nfor i in range(N_FOLDS):\n    p_lgb = models_lgb[i].predict(X_test)\n    p_xgb = models_xgb[i].predict(dtest)\n    p_cat = models_cat[i].predict_proba(X_test)[:,1]\n    sub_preds += (p_lgb + p_xgb + p_cat)/3\n\nsub_preds /= N_FOLDS\n\nprint(\"Test prediction OK.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-27T11:28:34.504051Z","iopub.execute_input":"2025-11-27T11:28:34.504218Z","iopub.status.idle":"2025-11-27T11:28:38.685164Z","shell.execute_reply.started":"2025-11-27T11:28:34.504205Z","shell.execute_reply":"2025-11-27T11:28:38.684308Z"}},"outputs":[{"name":"stdout","text":"Loading TEST splits...\nTest prediction OK.\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"threshold_list = [best_thr, \n                  best_thr-0.01,\n                  best_thr+0.01,\n                  best_thr-0.02,\n                  best_thr+0.02]\n\nprint(\"Use thresholds:\", threshold_list)\n\nfor idx, thr in enumerate(threshold_list,1):\n    pred = (sub_preds >= thr).astype(int)\n\n    sub_df = pd.DataFrame({\n        \"object_id\": test[\"object_id\"],\n        \"prediction\": pred\n    })\n\n    fname = f\"submission_FE32_thr{idx}_{thr:.3f}.csv\"\n    sub_df.to_csv(fname,index=False)\n\n    print(f\"Saved {fname} | positives = {pred.sum()}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-27T11:28:38.685976Z","iopub.execute_input":"2025-11-27T11:28:38.686199Z","iopub.status.idle":"2025-11-27T11:28:38.720572Z","shell.execute_reply.started":"2025-11-27T11:28:38.686180Z","shell.execute_reply":"2025-11-27T11:28:38.719797Z"}},"outputs":[{"name":"stdout","text":"Use thresholds: [0.1801507537688442, 0.1701507537688442, 0.19015075376884422, 0.16015075376884422, 0.2001507537688442]\nSaved submission_FE32_thr1_0.180.csv | positives = 388\nSaved submission_FE32_thr2_0.170.csv | positives = 410\nSaved submission_FE32_thr3_0.190.csv | positives = 365\nSaved submission_FE32_thr4_0.160.csv | positives = 441\nSaved submission_FE32_thr5_0.200.csv | positives = 342\n","output_type":"stream"}],"execution_count":15}]}